{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674591381872214\n",
      "0.6727941176470589\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils as ut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from time import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from rumex_model import RumexNet\n",
    "from trainer import train, validate\n",
    "from rumex_dataset import RumexDataset, train_loader, test_loader\n",
    "\n",
    "# mnasnet: 1e-3, 1e-2\n",
    "# shufflenet: 5e-3, 5e-2\n",
    "# mobilenet: 1e-4, 7e-3\n",
    "# densenet: 1e-4, 1e-3\n",
    "# resnet: 1e-4, 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_dir = '/u/21/hiremas1/unix/postdoc/rumex/data256_for_training/'\n",
    "model_name = 'shufflenet'\n",
    "base_lr = 5e-3\n",
    "max_lr = 5e-2\n",
    "log_dir = 'logs/'+model_name \n",
    "bs = 32\n",
    "\n",
    "\n",
    "dstr = RumexDataset(data_dir+'train/', train_flag=True)\n",
    "dltr = train_loader(dstr, bs)\n",
    "dsva = RumexDataset(data_dir+'valid/', train_flag=False)\n",
    "dlva = test_loader(dsva, bs)\n",
    "\n",
    "n1tr = dltr.dataset.rumex.targets.count(1)\n",
    "n0tr = dltr.dataset.rumex.targets.count(0) \n",
    "n1va = dlva.dataset.rumex.targets.count(1)\n",
    "n0va = dlva.dataset.rumex.targets.count(0)\n",
    "print(n0tr/(n0tr+n1tr))\n",
    "print(n0va/(n0va+n1va))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:0|et:2.747|loss_tr:0.58490|loss: 0.71094|acc:0.67279|re:0.00000|pre:nan|f1:nan|auc:0.59141\n",
      "ep:1|et:1.547|loss_tr:0.51152|loss: 0.64708|acc:0.67279|re:0.00000|pre:nan|f1:nan|auc:0.60142\n",
      "ep:2|et:1.557|loss_tr:0.44758|loss: 0.63946|acc:0.67279|re:0.00000|pre:nan|f1:nan|auc:0.60428\n",
      "ep:3|et:1.706|loss_tr:0.46137|loss: 0.63226|acc:0.67279|re:0.00000|pre:nan|f1:nan|auc:0.54686\n",
      "ep:4|et:1.691|loss_tr:0.48438|loss: 0.63873|acc:0.67279|re:0.00000|pre:nan|f1:nan|auc:0.67087\n",
      "ep:5|et:1.642|loss_tr:0.46617|loss: 0.69702|acc:0.67279|re:0.00562|pre:0.50000|f1:0.01111|auc:0.78299\n",
      "ep:6|et:1.539|loss_tr:0.49755|loss: 0.65622|acc:0.73713|re:0.23596|pre:0.85714|f1:0.37004|auc:0.72536\n",
      "ep:7|et:1.534|loss_tr:0.46115|loss: 0.65489|acc:0.65441|re:0.01685|pre:0.18750|f1:0.03093|auc:0.64511\n",
      "ep:8|et:1.571|loss_tr:0.48928|loss: 0.59682|acc:0.77022|re:0.48315|pre:0.72269|f1:0.57912|auc:0.78650\n",
      "ep:9|et:1.538|loss_tr:0.45521|loss: 1.55901|acc:0.68750|re:0.11798|pre:0.61765|f1:0.19811|auc:0.66278\n",
      "ep:10|et:1.569|loss_tr:0.51459|loss: 1.74558|acc:0.67279|re:0.00000|pre:nan|f1:nan|auc:0.44555\n",
      "ep:11|et:1.561|loss_tr:0.55598|loss: 0.60210|acc:0.70772|re:0.66854|pre:0.54338|f1:0.59950|auc:0.75560\n",
      "ep:12|et:1.531|loss_tr:0.49090|loss: 0.64473|acc:0.68015|re:0.02809|pre:0.83333|f1:0.05435|auc:0.59775\n",
      "ep:13|et:1.519|loss_tr:0.49576|loss: 0.84185|acc:0.77022|re:0.60674|pre:0.66258|f1:0.63343|auc:0.81172\n",
      "ep:14|et:1.540|loss_tr:0.52170|loss: 0.69375|acc:0.67279|re:0.00000|pre:nan|f1:nan|auc:0.30993\n",
      "ep:15|et:1.527|loss_tr:0.53313|loss: 1.79028|acc:0.55147|re:0.92697|pre:0.41667|f1:0.57491|auc:0.73560\n",
      "ep:16|et:1.545|loss_tr:0.48686|loss: 9.86049|acc:0.32721|re:1.00000|pre:0.32721|f1:0.49307|auc:0.65327\n",
      "ep:17|et:1.553|loss_tr:0.48045|loss: 1.04994|acc:0.32721|re:1.00000|pre:0.32721|f1:0.49307|auc:0.62293\n",
      "ep:18|et:1.564|loss_tr:0.48304|loss: 0.59368|acc:0.78125|re:0.51124|pre:0.73984|f1:0.60465|auc:0.81306\n",
      "ep:19|et:1.543|loss_tr:0.43770|loss: 18.48616|acc:0.40441|re:0.92697|pre:0.34664|f1:0.50459|auc:0.63104\n"
     ]
    }
   ],
   "source": [
    "model = RumexNet(model_name)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=base_lr, weight_decay=1e-2)\n",
    "scheduler = optim.lr_scheduler.CyclicLR(optimizer,\n",
    "                                        step_size_up=500,\n",
    "                                        cycle_momentum=False,\n",
    "                                        base_lr=base_lr,\n",
    "                                        max_lr=max_lr)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_val_acc = 0.5\n",
    "num_epochs=20\n",
    "history= np.zeros((num_epochs, 5))\n",
    "for ep in np.arange(num_epochs):\n",
    "    start = time()\n",
    "\n",
    "    #### fit model ##########\n",
    "    loss = train(model, dltr, optimizer, scheduler, loss_fn, device)\n",
    "\n",
    "    ##### Model Validation ##########\n",
    "    predictions, metrics = validate(model, dlva, loss_fn, device)\n",
    "\n",
    "    history[ep, 0] = loss # training loss\n",
    "    history[ep, 1] = metrics[\"loss\"] # validation loss\n",
    "    history[ep, 2] = metrics[\"acc\"] # validation acc\n",
    "    history[ep, 3] = metrics[\"f1\"] # validation acc\n",
    "    history[ep, 4] = metrics[\"auc\"] # validation acc    \n",
    "\n",
    "    ##### checkpoint saving and logging ##########\n",
    "    if metrics['loss'] < best_val_loss:\n",
    "        best_val_loss = metrics['loss']\n",
    "        ckpt_dict = {'ep': ep,\n",
    "                     'state_dict': model.state_dict(),\n",
    "                     'optim_dict': optimizer.state_dict(),\n",
    "                     'predictions': predictions,\n",
    "                     'metrics': metrics}    \n",
    "        ut.save_ckpt(ckpt_dict, log_dir)\n",
    "\n",
    "    # tensorboad logging\n",
    "    writer.add_scalar('train/loss', loss, ep)\n",
    "    for key in metrics.keys():\n",
    "        name = 'val/'+key\n",
    "        writer.add_scalar(name, metrics[key], ep)   \n",
    "    \n",
    "    \n",
    "    et = time() - start\n",
    "    print(f\"ep:{ep}|et:{et:.3f}|loss_tr:{loss:.5f}|loss: {metrics['loss']:.5f}\" +\n",
    "          f\"|acc:{metrics['acc']:.5f}|re:{metrics['pre']:.5f}\" +\n",
    "          f\"|pre:{metrics['recall']:.5f}|f1:{metrics['f1']:.5f}|auc:{metrics['auc']:.5f}\")\n",
    "\n",
    "np.save(log_dir+\"/history.npy\", history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history[:, 0])\n",
    "plt.plot(history[:, 1])\n",
    "plt.plot(history[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
