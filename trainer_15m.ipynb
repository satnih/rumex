{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils as ut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from time import time\n",
    "import utils as ut\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "device = torch.device(\"gpu\")\n",
    "\n",
    "def compute_metrics(y, yhat, score1):\n",
    "    y = y.detach().cpu().numpy()\n",
    "    yhat = yhat.detach().cpu().numpy()\n",
    "    score1 = score1.detach().cpu().numpy()\n",
    "\n",
    "    # macro weighs each class equally\n",
    "    # micro weights classes based on class prior\n",
    "    # micro=macro if classes balanced\n",
    "    # in binary classification; micro=macro\n",
    "    auc = roc_auc_score(y, score1)\n",
    "    acc = accuracy_score(y, yhat)\n",
    "    r1 = recall_score(y, yhat)\n",
    "    p1 = precision_score(y, yhat)\n",
    "    f1 = f1_score(y, yhat)\n",
    "    metrics = {\n",
    "        'acc': acc,\n",
    "        'f1': f1,\n",
    "        'p1': p1,  # precision for class 1\n",
    "        'r1': r1,  # recall for class 1\n",
    "        'auc': auc\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_loader, device):\n",
    "    ntrain = len(train_loader.dataset)\n",
    "    model = model.to(device)\n",
    "    running_loss_tr = 0.0\n",
    "    model.train()\n",
    "    for x_tr_b, y_tr_b, _ in train_loader:\n",
    "        # Forward pass\n",
    "        x_tr_b = x_tr_b.to(device)\n",
    "        y_tr_b = y_tr_b.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        score_tr_b = model(x_tr_b)\n",
    "        # loss of each elem in batch\n",
    "        loss_tr_b = loss_fn(score_tr_b, y_tr_b)\n",
    "        loss_tr_mean_b = torch.mean(loss_tr_b)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss_tr_mean_b.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        running_loss_tr += torch.sum(loss_tr_b)\n",
    "        loss_tr = running_loss_tr / ntrain\n",
    "    return model, optimizer, loss_tr\n",
    "\n",
    "def test(model, loss_fn, val_loader, device):\n",
    "    nval = len(val_loader.dataset)\n",
    "    ##### Model Validation ##########\n",
    "    y_val = []\n",
    "    score_val = []\n",
    "    yhat_val = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        running_loss_val = 0\n",
    "        for x_val_b, y_val_b, _ in val_loader:\n",
    "            x_val_b = x_val_b.to(device)\n",
    "            y_val_b = y_val_b.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            score_val_b = model(x_val_b)  # logits\n",
    "            _, yhat_val_b = torch.max(score_val_b, 1)\n",
    "            lossb_val = loss_fn(score_val_b, y_val_b)\n",
    "\n",
    "            # book keeping at batch level\n",
    "            running_loss_val += torch.sum(lossb_val)\n",
    "\n",
    "            y_val.append(y_val_b)\n",
    "            score_val.append(score_val_b)\n",
    "            yhat_val.append(yhat_val_b)\n",
    "\n",
    "        loss_val = running_loss_val / nval\n",
    "        # loss_val.append(loss_val)\n",
    "\n",
    "        # predictions and  metrics\n",
    "        y_val = torch.cat(y_val)\n",
    "        score_val = torch.cat(score_val)\n",
    "        yhat_val = torch.cat(yhat_val)\n",
    "\n",
    "        metrics = compute_metrics(y_val, yhat_val, score_val[:, 1])\n",
    "    return loss_val, metrics\n",
    "\n",
    "# mem_params = sum([param.nelement()*param.element_size() for param in model.parameters()])\n",
    "# mem_bufs = sum([buf.nelement()*buf.element_size() for buf in model.buffers()])\n",
    "# mem = mem_params + mem_bufs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"main\":\n",
    "    base_dir = \"data/15m/224/\"\n",
    "    train_dir = base_dir + \"test/\"\n",
    "    valid_dir = base_dir + \"train/\"\n",
    "\n",
    "    num_epochs=10\n",
    "    bs = 16\n",
    "\n",
    "    # dataset and data loader\n",
    "    dstr = ut.RumexDataset(train_dir)\n",
    "    dltr = ut.train_loader(dstr, bs)\n",
    "\n",
    "    dsva = ut.RumexDataset(valid_dir)\n",
    "    dlva = ut.test_loader(dsva, bs)\n",
    "\n",
    "    dste = ut.RumexDataset(test_dir)\n",
    "    dlte = ut.test_loader(dste, bs)\n",
    "\n",
    "    model = torch.load(\"results/10m/from_triton/resnet_trainer.pt\")\n",
    "    model = model.model\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:0|tr: 0.52583|loss: 9.28644|acc:0.73836|auc:0.30018|f1:0.06349|p1:0.22222|r1:0.03704\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "for ep in np.arange(num_epochs):\n",
    "    model, optimizer, loss_tr = train(model, optimizer, loss_fn, dltr, device)\n",
    "    loss_va, metrics = test(model, loss_fn, dlva, device)\n",
    "#     print(f\"ep:{ep}|loss_tr: {loss_tr:.5f}|loss_va: {loss_va:.5f}\")\n",
    "    \n",
    "#     if ep % 10 == 0:\n",
    "    print(f\"ep:{ep}|tr: {loss_tr:.5f}|loss: {loss_va:.5f}|acc:{metrics['acc']:.5f}\" +\n",
    "          f\"|auc:{metrics['auc']:.5f}|f1:{metrics['f1']:.5f}|p1:{metrics['p1']:.5f}|r1:{metrics['r1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = np.inf\n",
    "best_val_acc = 0.5\n",
    "num_epochs=20\n",
    "# history= np.zeros((num_epochs, 5))\n",
    "for ep in np.arange(num_epochs):\n",
    "    start = time()\n",
    "\n",
    "    #### fit model ##########\n",
    "    loss = train(model, dltr, optimizer, scheduler, loss_fn, device)\n",
    "\n",
    "    ##### Model Validation ##########\n",
    "    predictions, metrics = validate(model, dlva, loss_fn, device)\n",
    "\n",
    "    history[ep, 0] = loss # training loss\n",
    "    history[ep, 1] = metrics[\"loss\"] # validation loss\n",
    "    history[ep, 2] = metrics[\"acc\"] # validation acc\n",
    "    history[ep, 3] = metrics[\"f1\"] # validation acc\n",
    "    history[ep, 4] = metrics[\"auc\"] # validation acc    \n",
    "\n",
    "    ##### checkpoint saving and logging ##########\n",
    "    if metrics['loss'] < best_val_loss:\n",
    "        best_val_loss = metrics['loss']\n",
    "        ckpt_dict = {'ep': ep,\n",
    "                     'state_dict': model.state_dict(),\n",
    "                     'optim_dict': optimizer.state_dict(),\n",
    "                     'predictions': predictions,\n",
    "                     'metrics': metrics}    \n",
    "        ut.save_ckpt(ckpt_dict, log_dir)\n",
    "\n",
    "    # tensorboad logging\n",
    "    writer.add_scalar('train/loss', loss, ep)\n",
    "    for key in metrics.keys():\n",
    "        name = 'val/'+key\n",
    "        writer.add_scalar(name, metrics[key], ep)   \n",
    "    \n",
    "    \n",
    "    et = time() - start\n",
    "    print(f\"ep:{ep}|et:{et:.3f}|loss_tr:{loss:.5f}|loss: {metrics['loss']:.5f}\" +\n",
    "          f\"|acc:{metrics['acc']:.5f}|re:{metrics['pre']:.5f}\" +\n",
    "          f\"|pre:{metrics['recall']:.5f}|f1:{metrics['f1']:.5f}|auc:{metrics['auc']:.5f}\")\n",
    "\n",
    "# np.save(log_dir+\"/history.npy\", history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history[:, 0])\n",
    "plt.plot(history[:, 1])\n",
    "plt.plot(history[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
